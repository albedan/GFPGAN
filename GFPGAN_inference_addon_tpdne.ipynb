{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GFPGAN_inference_addon_tpdne.ipynb","provenance":[{"file_id":"1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo","timestamp":1639435817355},{"file_id":"https://github.com/xinntao/BasicSR/blob/add_colab/colab/BasicSR_inference_ESRGAN.ipynb","timestamp":1601814719353}],"collapsed_sections":["RJtKN6ANUADM"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RJtKN6ANUADM"},"source":["# GFPGAN Inference Demo \n","### (No colorization; No CUDA extensions required)\n","\n","[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n","[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n","[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n","\n","## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n","\n","GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n","It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n","\n","If you want to use the paper model, please go to this [Colab Demo](https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN <a href=\"https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"google colab logo\"></a>.\n","\n","**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n","\n","###Enjoy! :-)\n","\n","<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"]},{"cell_type":"markdown","metadata":{"id":"ZY1Zbo3uUkXg"},"source":["# 1. Preparations\n","Before start, make sure that you choose\n","* Runtime Type = Python 3\n","* Hardware Accelerator = GPU\n","\n","in the **Runtime** menu -> **Change runtime type**\n","\n","Then, we clone the repository, set up the envrironment, and download the pre-trained model.\n"]},{"cell_type":"code","metadata":{"id":"ZwH2ifWEYEfJ"},"source":["# Clone GFPGAN and enter the GFPGAN folder\n","%cd /content\n","!rm -rf GFPGAN\n","!git clone https://github.com/TencentARC/GFPGAN.git\n","%cd GFPGAN\n","\n","# Set up the environment\n","# Install basicsr - https://github.com/xinntao/BasicSR\n","# We use BasicSR for both training and inference\n","!pip install basicsr\n","# Install facexlib - https://github.com/xinntao/facexlib\n","# We use face detection and face restoration helper in the facexlib package\n","!pip install facexlib\n","# Install other depencencies\n","!pip install -r requirements.txt\n","!python setup.py develop\n","!pip install realesrgan  # used for enhancing the background (non-face) regions\n","# Download the pre-trained model\n","!wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-8JxpPwg4Xz"},"source":["# 2. Upload Images / Use the demo images"]},{"cell_type":"code","metadata":{"id":"CdMZYp0T7NAy"},"source":["# upload your own images\n","import os\n","from google.colab import files\n","import shutil\n","\n","upload_folder = 'inputs/upload'\n","\n","if os.path.isdir(upload_folder):\n","    shutil.rmtree(upload_folder)\n","os.mkdir(upload_folder)\n","\n","# upload images\n","uploaded = files.upload()\n","for filename in uploaded.keys():\n","  dst_path = os.path.join(upload_folder, filename)\n","  print(f'move {filename} to {dst_path}')\n","  shutil.move(filename, dst_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9dZUYDlMeXKe"},"source":["### OR you can use the demo image by running the following codes"]},{"cell_type":"code","metadata":{"id":"d6CkQ2x-eSjH"},"source":["import shutil\n","from google.colab import files\n","import os\n","upload_folder = 'inputs/upload'\n","\n","if os.path.isdir(upload_folder):\n","    shutil.rmtree(upload_folder)\n","os.makedirs(upload_folder, exist_ok=True)\n","shutil.move('inputs/whole_imgs/Blake_Lively.jpg', 'inputs/upload/Blake_Lively.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### OR you can use This Person Doesn't Exist"],"metadata":{"id":"qIfe2-vkosEs"}},{"cell_type":"code","source":["!pip install opencv-python\n","\n","import shutil\n","from google.colab import files\n","import os\n","import requests\n","import cv2 as cv\n","upload_folder_raw = 'inputs/upload_raw'\n","upload_folder = 'inputs/upload'\n","\n","if os.path.isdir(upload_folder):\n","    shutil.rmtree(upload_folder)\n","os.makedirs(upload_folder, exist_ok=True)\n","if os.path.isdir(upload_folder_raw):\n","    shutil.rmtree(upload_folder_raw)\n","os.makedirs(upload_folder_raw, exist_ok=True)\n","\n","image_url = 'https://thispersondoesnotexist.com/image'\n","filename_raw = upload_folder_raw + '/random_person_raw.jpg'\n","\n","r = requests.get(image_url, stream = True)\n","r.raw.decode_content = True\n","with open(filename_raw,'wb') as f:\n","        shutil.copyfileobj(r.raw, f)\n","\n","img = cv.imread(upload_folder_raw + '/random_person_raw.jpg')\n","blur = cv.GaussianBlur(img,(31,31),11)\n","cv.imwrite(upload_folder + '/random_person_blur.jpg', blur)"],"metadata":{"id":"5qLrCo6eoxpa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lGHc73Up70ZA"},"source":["# 3. Inference"]},{"cell_type":"code","metadata":{"id":"lmQVC3s97z4z"},"source":["# Now we use the GFPGAN to restore the above low-quality images\n","# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n","!rm -rf results\n","!python inference_gfpgan.py --upscale 2 --test_path inputs/upload --save_root results --model_path experiments/pretrained_models/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler realesrgan\n","\n","!ls results/cmp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkF8VAiF7-PY"},"source":["# 4. Visualize (ONLY for default images / user input images)"]},{"cell_type":"code","metadata":{"id":"tIeL_NJO8A3B"},"source":["# We first visualize the cropped faces\n","# The left are the inputs images; the right are the results of GFPGAN\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","def display(img1, img2):\n","  fig = plt.figure(figsize=(25, 10))\n","  ax1 = fig.add_subplot(1, 2, 1) \n","  plt.title('Input image', fontsize=16)\n","  ax1.axis('off')\n","  ax2 = fig.add_subplot(1, 2, 2)\n","  plt.title('GFPGAN output', fontsize=16)\n","  ax2.axis('off')\n","  ax1.imshow(img1)\n","  ax2.imshow(img2)\n","def imread(img_path):\n","  img = cv2.imread(img_path)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  return img\n","\n","# display each image in the upload folder\n","import os\n","import glob\n","\n","input_folder = 'results/cropped_faces'\n","result_folder = 'results/restored_faces'\n","input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n","output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n","for input_path, output_path in zip(input_list, output_list):\n","  img_input = imread(input_path)\n","  img_output = imread(output_path)\n","  display(img_input, img_output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn_2ylqP9qXY"},"source":["# We then visualize the whole image\n","# The left are the inputs images; the right are the results of GFPGAN\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","def display(img1, img2):\n","  fig = plt.figure(figsize=(25, 10))\n","  ax1 = fig.add_subplot(1, 2, 1) \n","  plt.title('Input image', fontsize=16)\n","  ax1.axis('off')\n","  ax2 = fig.add_subplot(1, 2, 2)\n","  plt.title('GFPGAN output', fontsize=16)\n","  ax2.axis('off')\n","  ax1.imshow(img1)\n","  ax2.imshow(img2)\n","def imread(img_path):\n","  img = cv2.imread(img_path)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  return img\n","\n","# display each image in the upload folder\n","import os\n","import glob\n","\n","input_folder = 'inputs/upload'\n","result_folder = 'results/restored_imgs'\n","input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n","output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n","for input_path, output_path in zip(input_list, output_list):\n","  img_input = imread(input_path)\n","  img_output = imread(output_path)\n","  display(img_input, img_output)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## OR Visualize (Only for This Person Doesn't Exist images)"],"metadata":{"id":"wHqUAZhA2Q2M"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","def display(img1, img2, img3):\n","  fig = plt.figure(figsize=(25, 10))\n","  ax1 = fig.add_subplot(1, 3, 1) \n","  plt.title('Original image', fontsize=16)\n","  ax1.axis('off')\n","  ax2 = fig.add_subplot(1, 3, 2)\n","  plt.title('Blurred image', fontsize=16)\n","  ax2.axis('off')\n","  ax3 = fig.add_subplot(1, 3, 3)\n","  plt.title('GFPGAN output restored from blurred', fontsize=16)\n","  ax3.axis('off')\n","  ax1.imshow(img1)\n","  ax2.imshow(img2)\n","  ax3.imshow(img3)\n","def imread(img_path):\n","  img = cv2.imread(img_path)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  return img\n","\n","# display each image in the upload folder\n","import os\n","import glob\n","\n","input_folder = 'inputs/upload_raw'\n","blur_folder = 'inputs/upload'\n","result_folder = 'results/restored_imgs'\n","input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n","blur_list = sorted(glob.glob(os.path.join(blur_folder, '*')))\n","output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n","for input_path, blur_path, output_path in zip(input_list, blur_list, output_list):\n","  img_input = imread(input_path)\n","  img_blur = imread(blur_path)\n","  img_output = imread(output_path)\n","  display(img_input, img_blur, img_output)"],"metadata":{"id":"JITTrnTi2Qkc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HR7VEBEb8slX"},"source":["# 5. Download results"]},{"cell_type":"code","source":[" # download the input\n","!ls inputs\n","print('Download inputs')\n","os.system('zip -r download_inputs.zip inputs')\n","files.download(\"download_inputs.zip\")"],"metadata":{"id":"EZJPLgn44G8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zuBCgeH08tdn"},"source":["# download the result\n","!ls results\n","print('Download results')\n","os.system('zip -r download_results.zip results')\n","files.download(\"download_results.zip\")"],"execution_count":null,"outputs":[]}]}